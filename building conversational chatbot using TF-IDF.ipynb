{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building a conversational chatbot for store's answer to questions with TF=IDF\n",
    "# Reference: \"Python Deep Learning Projects\", M. Lamons, R. Kumar, A. Nagaraja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 1: prepare the dataset and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import operator ,os\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            Question  \\\n",
      "0          When does your shop open?   \n",
      "1           What is today's special?   \n",
      "2  What is the cost of an americano?   \n",
      "3            Do you sell Ice-creams?   \n",
      "\n",
      "                                              Answer  \n",
      "0  Our shop timings are 9:00 am - 9:00 pm on week...  \n",
      "1  Today we have variety of Italian pasta, with s...  \n",
      "2  Americano with a single shot will cost 1.4$ an...  \n",
      "3  We do have desserts like ice-cream, brownies, ...  \n"
     ]
    }
   ],
   "source": [
    "filepath='sample_data.csv'\n",
    "csv_reader =pd.read_csv(filepath)\n",
    "print(csv_reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_list = csv_reader[csv_reader.columns[0]].values.tolist()\n",
    "answers_list  = csv_reader[csv_reader.columns[1]].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['When does your shop open?', \"What is today's special?\", 'What is the cost of an americano?', 'Do you sell Ice-creams?']\n"
     ]
    }
   ],
   "source": [
    "print(question_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "query ='can I get an Americano, btw how much it will cost ?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "                dtype=<class 'numpy.float64'>, encoding='ISO-8859-1',\n",
      "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
      "                min_df=0, ngram_range=(2, 4), norm='l2', preprocessor=None,\n",
      "                smooth_idf=True, stop_words=None, strip_accents='unicode',\n",
      "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, use_idf=True, vocabulary=None)\n"
     ]
    }
   ],
   "source": [
    "# creating the vector\n",
    "vectorizer = TfidfVectorizer(min_df=0, ngram_range=(2, 4), strip_accents='unicode',norm='l2' , encoding='ISO-8859-1')\n",
    "print(vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 2: train the model on the questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 9)\t0.3333333333333333\n",
      "  (0, 32)\t0.3333333333333333\n",
      "  (0, 37)\t0.3333333333333333\n",
      "  (0, 8)\t0.3333333333333333\n",
      "  (0, 31)\t0.3333333333333333\n",
      "  (0, 20)\t0.3333333333333333\n",
      "  (0, 36)\t0.3333333333333333\n",
      "  (0, 7)\t0.3333333333333333\n",
      "  (0, 30)\t0.3333333333333333\n",
      "  (1, 29)\t0.4217647821447532\n",
      "  (1, 15)\t0.4217647821447532\n",
      "  (1, 28)\t0.4217647821447532\n",
      "  (1, 24)\t0.4217647821447532\n",
      "  (1, 14)\t0.4217647821447532\n",
      "  (1, 25)\t0.3325241986862672\n",
      "  (2, 3)\t0.26151864623057924\n",
      "  (2, 23)\t0.26151864623057924\n",
      "  (2, 13)\t0.26151864623057924\n",
      "  (2, 27)\t0.26151864623057924\n",
      "  (2, 17)\t0.26151864623057924\n",
      "  (2, 2)\t0.26151864623057924\n",
      "  (2, 22)\t0.26151864623057924\n",
      "  (2, 12)\t0.26151864623057924\n",
      "  (2, 26)\t0.26151864623057924\n",
      "  (2, 0)\t0.26151864623057924\n",
      "  (2, 16)\t0.26151864623057924\n",
      "  (2, 1)\t0.26151864623057924\n",
      "  (2, 21)\t0.26151864623057924\n",
      "  (2, 11)\t0.26151864623057924\n",
      "  (2, 25)\t0.20618430452425712\n",
      "  (3, 35)\t0.3333333333333333\n",
      "  (3, 6)\t0.3333333333333333\n",
      "  (3, 19)\t0.3333333333333333\n",
      "  (3, 34)\t0.3333333333333333\n",
      "  (3, 5)\t0.3333333333333333\n",
      "  (3, 10)\t0.3333333333333333\n",
      "  (3, 18)\t0.3333333333333333\n",
      "  (3, 33)\t0.3333333333333333\n",
      "  (3, 4)\t0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "X_train = vectorizer.fit_transform(np.array([''.join(que) for que in question_list]))\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 3: transform the query to chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t1.0\n"
     ]
    }
   ],
   "source": [
    "X_query=vectorizer.transform([query])\n",
    "print(X_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 4: computing similarity score for the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.26151864623057924, 0.0]\n"
     ]
    }
   ],
   "source": [
    "XX_similarity=np.dot(X_train.todense(), X_query.transpose().todense())\n",
    "XX_sim_scores= np.array(XX_similarity).flatten().tolist()\n",
    "print(XX_sim_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 5; ranking results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_sim= dict(enumerate(XX_sim_scores))\n",
    "sorted_dict_sim = sorted(dict_sim.items(), key=operator.itemgetter(1), reverse =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 6: retrieve the answer result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Americano with a single shot will cost 1.4$ and the double shot will cost 2.3$.\n"
     ]
    }
   ],
   "source": [
    "# checking the index with the most similar question and the response with the index\n",
    "if sorted_dict_sim[0][1]==0:\n",
    "    print(\"Sorry I have no answer, please try asking again in a nicer way :)\")\n",
    "    resp = \"Sorry I have no answer, please try asking again in a nicer way :)\"\n",
    "elif sorted_dict_sim[0][1]>0:\n",
    "    print (answers_list [sorted_dict_sim[0][0]])        \n",
    "    resp = answers_list [sorted_dict_sim[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We do have desserts like ice-cream, brownies, and pastries.\n"
     ]
    }
   ],
   "source": [
    "query ='do you have fruits ?'\n",
    "X_query=vectorizer.transform([query])\n",
    "XX_similarity=np.dot(X_train.todense(), X_query.transpose().todense())\n",
    "XX_sim_scores= np.array(XX_similarity).flatten().tolist()\n",
    "dict_sim= dict(enumerate(XX_sim_scores))\n",
    "sorted_dict_sim = sorted(dict_sim.items(), key=operator.itemgetter(1), reverse =True)\n",
    "if sorted_dict_sim[0][1]==0:\n",
    "    print(\"Sorry I have no answer, please try asking again in a nicer way :)\")\n",
    "    resp = \"Sorry I have no answer, please try asking again in a nicer way :)\"\n",
    "elif sorted_dict_sim[0][1]>0:\n",
    "    print (answers_list [sorted_dict_sim[0][0]])        \n",
    "    resp = answers_list [sorted_dict_sim[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
